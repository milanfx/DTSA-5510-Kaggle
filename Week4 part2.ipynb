{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE. You should use sklearn library. [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.spatial.distance import jaccard, cosine \n",
    "from pytest import approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('data/users.csv')\n",
    "MV_movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys():\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.allusers = list(self.data.users['uID'])\n",
    "        self.allmovies = list(self.data.movies['mID'])\n",
    "        self.genres = list(self.data.movies.columns.drop(['mID', 'title', 'year']))\n",
    "        self.mid2idx = dict(zip(self.data.movies.mID,list(range(len(self.data.movies)))))\n",
    "        self.uid2idx = dict(zip(self.data.users.uID,list(range(len(self.data.users)))))\n",
    "        self.Mr=self.rating_matrix()\n",
    "        self.Mm=None \n",
    "        self.sim=np.zeros((len(self.allmovies),len(self.allmovies)))\n",
    "        \n",
    "    def rating_matrix(self):\n",
    "        \"\"\"\n",
    "        Convert the rating matrix to numpy array of shape (#allusers,#allmovies)\n",
    "        \"\"\"\n",
    "        ind_movie = [self.mid2idx[x] for x in self.data.train.mID] \n",
    "        ind_user = [self.uid2idx[x] for x in self.data.train.uID]\n",
    "        rating_train = list(self.data.train.rating)\n",
    "        return np.array(coo_matrix((rating_train, (ind_user, ind_movie)), shape=(len(self.allusers), len(self.allmovies))).toarray())\n",
    "\n",
    "    def predict_everything_to_3(self):\n",
    "        \"\"\"\n",
    "        Predict everything to 3 for the test data\n",
    "        \"\"\"\n",
    "        # Generate an array with 3s against all entries in test dataset\n",
    "        # your code here\n",
    "        y_pred = np.full(len(self.data.test), 3)\n",
    "        return y_pred\n",
    "        \n",
    "    def predict_to_user_average(self):\n",
    "        \"\"\"\n",
    "        Predict to average rating for the user.\n",
    "        Returns numpy array of shape (#users,)\n",
    "        \"\"\"\n",
    "        # Generate an array as follows:\n",
    "        # 1. Calculate all avg user rating as sum of ratings of user across all movies/number of movies whose rating > 0\n",
    "        # 2. Return the average rating of users in test data\n",
    "        # your code here\n",
    "        user_ratings = self.Mr.sum(axis=1)\n",
    "        user_avg_ratings = user_ratings / (self.Mr > 0).sum(axis=1)\n",
    "        user_avg_pred = user_avg_ratings[[self.uid2idx[x] for x in self.data.test.uID]]\n",
    "        return user_avg_pred\n",
    "        pass\n",
    "    \n",
    "    def predict_from_sim(self,uid,mid):\n",
    "        \"\"\"\n",
    "        Predict a user rating on a movie given userID and movieID\n",
    "        \"\"\"\n",
    "        # Predict user rating as follows:\n",
    "        # 1. Get entry of user id in rating matrix\n",
    "        # 2. Get entry of movie id in sim matrix\n",
    "        # 3. Employ 1 and 2 to predict user rating of the movie\n",
    "        # your code here\n",
    "        user_feature = self.Mr[self.uid2idx[uid]]\n",
    "        movie_feature = self.sim[self.mid2idx[mid]]\n",
    "        return np.dot(user_feature, movie_feature) / np.dot(movie_feature, user_feature> 0)     \n",
    "        pass\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict ratings in the test data. Returns predicted rating in a numpy array of size (# of rows in testdata,)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        y_pred=[]\n",
    "        for i in range(len(self.data.test)):\n",
    "            row = self.data.test.loc[i]\n",
    "            uid = row.uID\n",
    "            mid = row.mID\n",
    "            y_pred.append(self.predict_from_sim(uid, mid))\n",
    "        return np.array(y_pred)                                  \n",
    "        pass\n",
    "    \n",
    "    def rmse(self,yp):\n",
    "        yp[np.isnan(yp)]=3 #In case there is nan values in prediction, it will impute to 3.\n",
    "        yt=np.array(self.data.test.rating)\n",
    "        return np.sqrt(((yt-yp)**2).mean())\n",
    "\n",
    "    \n",
    "class ContentBased(RecSys):\n",
    "    def __init__(self,data):\n",
    "        super().__init__(data)\n",
    "        self.data=data\n",
    "        self.Mm = self.calc_movie_feature_matrix()  \n",
    "        \n",
    "    def calc_movie_feature_matrix(self):\n",
    "        \"\"\"\n",
    "        Create movie feature matrix in a numpy array of shape (#allmovies, #genres) \n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        genre = self.data.movies[self.genres].values\n",
    "        return genre\n",
    "        pass\n",
    "    \n",
    "    def calc_item_item_similarity(self):\n",
    "        \"\"\"\n",
    "        Create item-item similarity using Jaccard similarity\n",
    "        \"\"\"\n",
    "        # Update the sim matrix by calculating item-item similarity using Jaccard similarity\n",
    "        # Jaccard Similarity: J(A, B) = |A∩B| / |A∪B| \n",
    "        # your code here\n",
    "        n_movies = len(self.allmovies)\n",
    "        self.sim = np.zeros((n_movies, n_movies))\n",
    "        for i in range(n_movies):\n",
    "            for j in range(i, n_movies):\n",
    "                inter = np.sum(np.logical_and(self.Mm[i], self.Mm[j]))\n",
    "                union = np.sum(np.logical_or(self.Mm[i], self.Mm[j]))\n",
    "                jaccard = inter / union\n",
    "                self.sim[i, j] = jaccard\n",
    "                self.sim[j, i] = jaccard\n",
    "                \n",
    "class Collaborative(RecSys):    \n",
    "    def __init__(self,data):\n",
    "        super().__init__(data)\n",
    "        \n",
    "    def calc_item_item_similarity(self, simfunction, *X):  \n",
    "        \"\"\"\n",
    "        Create item-item similarity using similarity function. \n",
    "        X is an optional transformed matrix of Mr\n",
    "        \"\"\"    \n",
    "        # General function that calculates item-item similarity based on the sim function and data inputed\n",
    "        if len(X)==0:\n",
    "            self.sim = simfunction()            \n",
    "        else:\n",
    "            self.sim = simfunction(X[0]) # *X passes in a tuple format of (X,), to X[0] will be the actual transformed matrix\n",
    "\n",
    "    def cossim(self):    \n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using cosine similarity (values from 0 to 1) on utility matrix\n",
    "        Returns a cosine similarity matrix of size (#all movies, #all movies)\n",
    "        \"\"\"\n",
    "        row_means = self.Mr.sum(axis=1) / (self.Mr > 0).sum(axis=1)\n",
    "        center_means = np.repeat(np.expand_dims(row_means, axis=1), self.Mr.shape[1], axis=1)\n",
    "        center_matrix = self.Mr + (self.Mr == 0) * center_means - center_means\n",
    "        norm_matrix = center_matrix / np.sqrt((center_matrix ** 2).sum(axis=0))\n",
    "        norm_matrix[np.isnan(norm_matrix)] = 0.\n",
    "        cos = np.dot(norm_matrix.T, norm_matrix)\n",
    "        for i in range(len(self.allmovies)):\n",
    "            cos[i, i] = 1\n",
    "        sim_matrix = 0.5*cos + 0.5\n",
    "        return sim_matrix\n",
    "        pass\n",
    "    \n",
    "    def jacsim(self,Xr):\n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using jaccard similarity (values from 0 to 1)\n",
    "        Xr is the transformed rating matrix.\n",
    "        \"\"\"\n",
    "        # Return a sim matrix by calculating item-item similarity for all pairs of items using Jaccard similarity\n",
    "        # Jaccard Similarity: J(A, B) = |A∩B| / |A∪B| \n",
    "        # your code here\n",
    "        n = Xr.shape[1]\n",
    "        max_Xr = int(Xr.max())\n",
    "        inter_matrix = np.zeros((n, n), dtype=int)\n",
    "        for i in range(1, max_Xr + 1):\n",
    "            csr = csr_matrix((Xr == i).astype(int))\n",
    "            inter_matrix += csr.T.dot(csr).toarray()\n",
    "            \n",
    "        csr_Xr = csr_matrix((Xr > 0).astype(int))\n",
    "        none0_inter = csr_Xr.T.dot(csr_Xr).toarray()\n",
    "        row_sum = (Xr > 0).sum(axis=0)\n",
    "        row_tile = np.repeat(row_sum.reshape((n, 1)), n, axis=1)\n",
    "        union_matrix = row_tile.T + row_tile - none0_inter\n",
    "        \n",
    "        inter_matrix = inter_matrix.astype(np.float64)\n",
    "        union_matrix = union_matrix.astype(np.float64)\n",
    "        jac_matrix = np.divide(inter_matrix, union_matrix, out=np.zeros_like(union_matrix), where=union_matrix != 0)\n",
    "        np.nan_to_num(jac_matrix, copy=False)\n",
    "        np.fill_diagonal(jac_matrix, 1)\n",
    "        return jac_matrix        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Simple Baseline Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2585510334053043\n"
     ]
    }
   ],
   "source": [
    "# Creating Sample test data\n",
    "np.random.seed(42)\n",
    "sample_train = train[:30000]\n",
    "sample_test = test[:30000]\n",
    "\n",
    "\n",
    "sample_MV_users = MV_users[(MV_users.uID.isin(sample_train.uID)) | (MV_users.uID.isin(sample_test.uID))]\n",
    "sample_MV_movies = MV_movies[(MV_movies.mID.isin(sample_train.mID)) | (MV_movies.mID.isin(sample_test.mID))]\n",
    "\n",
    "\n",
    "sample_data = Data(sample_MV_users, sample_MV_movies, sample_train, sample_test)\n",
    "\n",
    "# Hidden tests predict_everything_to_3 in class RecSys\n",
    "rs = RecSys(data)\n",
    "yp = rs.predict_everything_to_3()\n",
    "print(rs.rmse(yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Best Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity calculation time 4.543038669973612\n",
      "0.9509126236828654\n"
     ]
    }
   ],
   "source": [
    "cf = Collaborative(data)\n",
    "Xr = cf.Mr.astype(int)\n",
    "t0=time.perf_counter()\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "t1=time.perf_counter()\n",
    "time_sim = t1-t0\n",
    "print('similarity calculation time',time_sim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "print(rmse)\n",
    "assert(rmse<0.96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 NMF Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ratings matrix\n",
    "rs = RecSys(data)\n",
    "ratings_matrix = rs.Mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF\n",
    "model = NMF(random_state=26,\n",
    "            n_components=10,\n",
    "            init='random',\n",
    "            solver='cd',\n",
    "            beta_loss='frobenius',\n",
    "            max_iter=200).fit(ratings_matrix)\n",
    "## Factorize the ratings matrix into two matrices \n",
    "W = model.transform(ratings_matrix)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9140986869248278\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct the ratings matrix using W and H\n",
    "reconstruct = model.inverse_transform(W)\n",
    "# Create a list of predicted ratings\n",
    "predicted_ratings = []\n",
    "n_test = len(rs.data.test)\n",
    "for i in range(n_test):\n",
    "    x = rs.data.test.iloc[i]\n",
    "    movie_id = x.mID\n",
    "    user_id = x.uID\n",
    "    predicted_ratings.append(reconstruct[rs.uid2idx[user_id], rs.mid2idx[movie_id]])\n",
    "## Create an array of actual ratings\n",
    "actual_ratings = np.array(rs.data.test.rating)\n",
    "nmf_rmse = np.sqrt(((actual_ratings-predicted_ratings)**2).mean())\n",
    "print(nmf_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Discuss the results and why sklearn's non-negative matrix facorization library did not work well compared to simple baseline or similarity-based methods we’ve done in Module 3. Can you suggest a way(s) to fix it? [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason: Most ratings are 0, which makes the matrix too sparse. The NMF model in sklearn is more suitable for computing relatively dense matrices. If the matrix is too sparse, additional processing is required. If the NMF model in sklearn is used directly, it will cause significant bias in matrix computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggestion: We can preprocess the data by setting unknown values to the median instead of 0, which can avoid such large errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
